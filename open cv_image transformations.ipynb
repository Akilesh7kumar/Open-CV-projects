{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(r\".\\images\\input.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "height,width = img.shape[:2]\n",
    "quarter_height,quarter_width = height/4 , width/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Translation\n",
    "# T=|1 0 Tx|\n",
    "#  |0 1  Ty|\n",
    "T = np.float32([[1,0,quarter_width],[0,1,quarter_height]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_trans = cv2.warpAffine(img,T,(width,height))\n",
    "cv2.imshow('Translation',img_trans)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.  ,   0.  , 155.5 ],\n",
       "       [  0.  ,   1.  , 103.75]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotation_matrix = cv2.getRotationMatrix2D((width/2,height/2), 90, .5)\n",
    "rotated_img = cv2.warpAffine(img,rotation_matrix,(width,height))\n",
    "cv2.imshow(\"Rotated img\",rotated_img)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rot_img = cv2.transpose(img)\n",
    "cv2.imshow(\"transp image\",rot_img)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling resizing interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#image 3/4 of original size\n",
    "img_scaled = cv2.resize(img,None,fx=0.75,fy=0.75)\n",
    "cv2.imshow(\"Scaling_linear interpolation\",img_scaled)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#doubling size of image\n",
    "img_scaled = cv2.resize(img,None,fx=0.75,fy=0.75,interpolation = cv2.INTER_CUBIC)\n",
    "cv2.imshow(\"Scaling_cibic interpolation\",img_scaled)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# skewing the resizing by fixing the  exavt dimensions\n",
    "img_scaled = cv2.resize(img,(900,400),interpolation = cv2.INTER_AREA)\n",
    "cv2.imshow(\"Scaling_skewed\",img_scaled)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image pyramids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small = cv2.pyrDown(img)\n",
    "large = cv2.pyrUp(img)\n",
    "cv2.imshow('small',small)\n",
    "cv2.imshow('large',large)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "height,width = img.shape[:2]\n",
    "start_row,start_col = int(height*0.30) ,int(width * 0.25)\n",
    "end_row,end_col = int(height*0.62) ,int(width * 0.75)\n",
    "cropped = img[start_row:end_row,start_col:end_col]\n",
    "cv2.imshow(\"cropped\",cropped)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arithmetc operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M= np.ones(img.shape,dtype=\"uint8\")*75\n",
    "added = cv2.add(img,M)\n",
    "cv2.imshow(\"Added\",added)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M= np.ones(img.shape,dtype=\"uint8\")*75\n",
    "subtract = cv2.subtract(img,M)\n",
    "cv2.imshow(\"Sub\",subtract)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bitwie operations and masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "square = np.zeros((300,300),np.uint8)\n",
    "cv2.rectangle(square,(50,50),(250,250),255,-2)\n",
    "cv2.imshow(\"square\",square)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ellipse = np.zeros((300,300),np.uint8)\n",
    "cv2.ellipse(ellipse,(150,150),(150,150),30,0,180,255,-1)\n",
    "cv2.imshow(\"square\",ellipse)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "And = cv2.bitwise_and(square,ellipse)\n",
    "cv2.imshow('and',And)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Or = cv2.bitwise_or(square,ellipse)\n",
    "cv2.imshow('or',Or)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xxor = cv2.bitwise_xor(square,ellipse)\n",
    "cv2.imshow('xor',xxor)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnot = cv2.bitwise_not(square,ellipse)\n",
    "cv2.imshow('not',nnot)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution and blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(r\".\\images\\elephant.jpg\")\n",
    "cv2.imshow(\"elepant\",img)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#kernel 3 x 3\n",
    "kernel_33 = np.ones((3,3),np.float32)/9\n",
    "blurred = cv2.filter2D(img,-1,kernel_33)\n",
    "cv2.imshow(\"blurr\",blurred)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#kernel 3 x 3\n",
    "kernel_33 = np.ones((3,3),np.float32)/49\n",
    "blurred = cv2.filter2D(img,-1,kernel_33)\n",
    "cv2.imshow(\"blurr\",blurred)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Averaging by convolving with the normalized box filter\n",
    "blur = cv2.blur(img,(3,3))\n",
    "cv2.imshow(\"blurr\",blur)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instead of box filter gaussian kernel\n",
    "Gaussian_blur = cv2.GaussianBlur(img,(7,7),0)\n",
    "cv2.imshow(\"blurr\",Gaussian_blur)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Takes median of all pixels under kernel area and kernel element is replaceed with median vbalue\n",
    "median_blur = cv2.medianBlur(img,5)\n",
    "cv2.imshow(\"blurr\",median_blur)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image denoising non local means denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parameters after none are the filter strngth components next is h for colored conponent\n",
    "dst = cv2.fastNlMeansDenoisingColored(img,None,6,6,7,21)\n",
    "cv2.imshow(\"Fast means denoising\",dst)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharpening"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "By altering pur kernel we can implement shaprpenig Kernel sum equals to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_sharpening = np.array([[-1,-1,-1],[-1,9,-1],[-1,-1,-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#kernel 3 x 3\n",
    "sharpened = cv2.filter2D(img,-1,kernel_sharpening)\n",
    "cv2.imshow(\"IMage sharpening\",sharpened)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thresholding ,binarization and adaptive thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(r\".\\images\\gradient.jpg\")\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#value below 127 goes to black everything above 127 goes to 255white\n",
    "ret,thresh1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "cv2.imshow('Thresh binary',thresh1)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#value below 127 goes to white everything above 127 goes to 0 black\n",
    "ret,thresh2 = cv2.threshold(img,127,255,cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow('Thresh binary inv',thresh2)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#value above 127 truncated (hold) at 127 \n",
    "ret,thresh4 = cv2.threshold(img,127,255,cv2.THRESH_TRUNC)\n",
    "cv2.imshow('Thresh trunc',thresh4)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#value below 127 goes to black\n",
    "ret,thresh5 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO)\n",
    "cv2.imshow('Thresh binary',thresh5)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reverse of above\n",
    "ret,thresh6 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO_INV)\n",
    "cv2.imshow('Thresh binary',thresh6)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dilation and erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dilation - add pixels to boundaries of object erosion- removes pixel at the boundaries of object\n",
    "#opening- erosion followed by dilation closing-dilation followed by erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(r'.\\images\\opencv_inv.png',0)\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#define kernel size\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "\n",
    "erosion = cv2.erode(img,kernel,iterations = 1)\n",
    "cv2.imshow('erosion',erosion)\n",
    "cv2.waitKey()\n",
    "\n",
    "dilation = cv2.dilate(img,kernel,iterations = 1)\n",
    "cv2.imshow('dilation',dilation)\n",
    "cv2.waitKey()\n",
    "\n",
    "\n",
    "opening = cv2.morphologyEx(img,cv2.MORPH_OPEN,kernel)\n",
    "cv2.imshow('opening',opening)\n",
    "cv2.waitKey()\n",
    "\n",
    "\n",
    "closing = cv2.morphologyEx(img,cv2.MORPH_CLOSE,kernel)\n",
    "cv2.imshow('closing',closing)\n",
    "cv2.waitKey()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge detection and image gradients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(r'.\\images\\input.jpg')\n",
    "height,width = img.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract sobel edges\n",
    "sobel_x = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5)\n",
    "sobel_y = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow('orginal',img)\n",
    "cv2.waitKey()\n",
    "cv2.imshow('sobel x',sobel_x)\n",
    "cv2.waitKey()\n",
    "cv2.imshow('sobel y',sobel_y)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laplacian = cv2.Laplacian(img,cv2.CV_64F)\n",
    "cv2.imshow('laplacian',laplacian)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Canny edge detection uses gradient value as thresholds\n",
    "canny = cv2.Canny(img,20,170)\n",
    "cv2.imshow('canny',canny)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting perpsective transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(r'.\\images\\scan.jpg')\n",
    "cv2.imshow('original',img)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'getPerspective'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-ddfa9894445c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mM\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetPerspectiveTransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpointA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpointB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mwarped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetPerspective\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m420\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m594\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'warppespactive'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwarped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'getPerspective'"
     ]
    }
   ],
   "source": [
    "pointA = np.float32([[320,15],[700,215],[85,610],[530,780]])\n",
    "pointB = np.float32([[0,0],[420,0],[0,594],[420,594]])\n",
    "\n",
    "M =cv2.getPerspectiveTransform(pointA,pointB)\n",
    "\n",
    "warped = cv2.getPerspective(img,M,(420,594))\n",
    "cv2.imshow('warppespactive',warped)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
